{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    try:\n",
    "        from pyspark.sql import SparkSession\n",
    "    except:\n",
    "        import findspark\n",
    "        findspark.init()\n",
    "        from pyspark.sql import SparkSession\n",
    "    spark=SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"kmeans\") \\\n",
    "    .getOrCreate()\n",
    "    sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=sc.parallelize([1,2,3,4])\n",
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=sc.parallelize(['manzana',1,1.4])\n",
    "r2=sc.parallelize([i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manzana', 1, 1.4]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(r1.collect())\n",
    "print(r2.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "4.5\n",
      "8.25\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(r2.count())\n",
    "print(r2.mean())\n",
    "print(r2.variance())\n",
    "print(r2.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apache Spark es un framework de computación en clúster open-source. Fue desarrollada originariamente en la Universidad de California, en el AMPLab de Berkeley. El código base del proyecto Spark fue donado más tarde a la Apache Software Foundation que se encarga de su mantenimiento desde entonces. Spark proporciona una interfaz para la programación de clusters completos con Paralelismo de Datos implícito y tolerancia a fallos.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=sc.textFile('textSpark.txt')\n",
    "#text.collect()\n",
    "text.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Acciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x,y):\n",
    "    return(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.reduce(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3=sc.parallelize(range(0,100),3)\n",
    "result=r3.reduce(lambda x,y:x-y)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3=sc.parallelize(range(0,5),2)\n",
    "r3.reduce(lambda x,y:x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.aggregate(0,lambda c,s:c+s.count('a'),lambda n1,n2:n1+n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=sc.parallelize(range(0,500),2)\n",
    "#number.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number.saveAsTextFile(\"C:\\tmp\\datos\\data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Transformacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremento(x):\n",
    "    return x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "PythonRDD[45] at collect at <ipython-input-31-1576fa55ef62>:2\n"
     ]
    }
   ],
   "source": [
    "r4=r2.map(incremento)\n",
    "print(r4.collect())\n",
    "print(r4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def par(x):\n",
    "    if x%2==0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8]\n",
      "<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "r5=r2.filter(par)\n",
    "print(r5.collect())\n",
    "print(type(r5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "r6=sc.parallelize(range(0,6))\n",
    "r7=sc.parallelize(range(5,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r8=r6.union(r7)\n",
    "r8.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r9=r6.intersection(r7)\n",
    "r9.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[('juan',29),('pedro',19),('jose',32)]\n",
    "df=spark.createDataFrame(l,['nombre','edad'])\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|nombre|edad|\n",
      "+------+----+\n",
      "|  juan|  29|\n",
      "| pedro|  19|\n",
      "|  jose|  32|\n",
      "+------+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nombre: string (nullable = true)\n",
      " |-- edad: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 2\n"
     ]
    }
   ],
   "source": [
    "if sc.version.startswith(\"2\"):\n",
    "     csv_plugin = \"csv\"\n",
    "     print('version 2')\n",
    "else:\n",
    "     csv_plugin = \"com.databricks.spark.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = sqlContext.read.format(csv_plugin).options(header='true', inferSchema='true').load('titanic.csv')\n",
    "type(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- n_siblings_spouses: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- deck: string (nullable = true)\n",
      " |-- embark_town: string (nullable = true)\n",
      " |-- alone: string (nullable = true)\n",
      "\n",
      "None\n",
      "627\n"
     ]
    }
   ],
   "source": [
    "df1=spark.read.csv('titanic.csv',header=True,inferSchema=True)\n",
    "print(type(df1))\n",
    "print(df1.printSchema())\n",
    "print(df1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.drop('survived','deck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- n_siblings_spouses: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- embark_town: string (nullable = true)\n",
      " |-- alone: string (nullable = true)\n",
      "\n",
      "+------+----+------------------+-----+-------+------+-----------+-----+\n",
      "|   sex| age|n_siblings_spouses|parch|   fare| class|embark_town|alone|\n",
      "+------+----+------------------+-----+-------+------+-----------+-----+\n",
      "|  male|22.0|                 1|    0|   7.25| Third|Southampton|    n|\n",
      "|female|38.0|                 1|    0|71.2833| First|  Cherbourg|    n|\n",
      "|female|26.0|                 0|    0|  7.925| Third|Southampton|    y|\n",
      "|female|35.0|                 1|    0|   53.1| First|Southampton|    n|\n",
      "|  male|28.0|                 0|    0| 8.4583| Third| Queenstown|    y|\n",
      "|  male| 2.0|                 3|    1| 21.075| Third|Southampton|    n|\n",
      "|female|27.0|                 0|    2|11.1333| Third|Southampton|    n|\n",
      "|female|14.0|                 1|    0|30.0708|Second|  Cherbourg|    n|\n",
      "|female| 4.0|                 1|    1|   16.7| Third|Southampton|    n|\n",
      "|  male|20.0|                 0|    0|   8.05| Third|Southampton|    y|\n",
      "|  male|39.0|                 1|    5| 31.275| Third|Southampton|    n|\n",
      "|female|14.0|                 0|    0| 7.8542| Third|Southampton|    y|\n",
      "|  male| 2.0|                 4|    1| 29.125| Third| Queenstown|    n|\n",
      "|  male|28.0|                 0|    0|   13.0|Second|Southampton|    y|\n",
      "|female|31.0|                 1|    0|   18.0| Third|Southampton|    n|\n",
      "|female|28.0|                 0|    0|  7.225| Third|  Cherbourg|    y|\n",
      "|  male|35.0|                 0|    0|   26.0|Second|Southampton|    y|\n",
      "|  male|28.0|                 0|    0|   35.5| First|Southampton|    y|\n",
      "|female|38.0|                 1|    5|31.3875| Third|Southampton|    n|\n",
      "|  male|28.0|                 0|    0|  7.225| Third|  Cherbourg|    y|\n",
      "+------+----+------------------+-----+-------+------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>29.631307814992027</td>\n",
       "      <td>0.5454545454545454</td>\n",
       "      <td>0.379585326953748</td>\n",
       "      <td>34.385398564593245</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>None</td>\n",
       "      <td>12.511817629565812</td>\n",
       "      <td>1.1510895973422302</td>\n",
       "      <td>0.7929992125432801</td>\n",
       "      <td>54.597730499456304</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>female</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary     sex                 age  n_siblings_spouses               parch  \\\n",
       "0   count     627                 627                 627                 627   \n",
       "1    mean    None  29.631307814992027  0.5454545454545454   0.379585326953748   \n",
       "2  stddev    None  12.511817629565812  1.1510895973422302  0.7929992125432801   \n",
       "3     min  female                0.75                   0                   0   \n",
       "4     max    male                80.0                   8                   5   \n",
       "\n",
       "                 fare  class embark_town alone  \n",
       "0                 627    627         627   627  \n",
       "1  34.385398564593245   None        None  None  \n",
       "2  54.597730499456304   None        None  None  \n",
       "3                 0.0  First   Cherbourg     n  \n",
       "4            512.3292  Third     unknown     y  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.printSchema()\n",
    "df1.show()\n",
    "df1.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Spark ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer,OneHotEncoderEstimator,VectorAssembler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_enc=StringIndexer(inputCol='sex',outputCol='sex_enc',stringOrderType='alphabetAsc')\n",
    "embark_enc=StringIndexer(inputCol='embark_town',outputCol='embark_enc',stringOrderType='alphabetAsc')\n",
    "class_enc=StringIndexer(inputCol='class',outputCol='class_enc',stringOrderType='alphabetAsc')\n",
    "alone_enc=StringIndexer(inputCol='alone',outputCol='alone_enc',stringOrderType='alphabetAsc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoderEstimator(inputCols=['sex_enc','embark_enc'],outputCols=['sex_ohe','embark_ohe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=VectorAssembler(inputCols=['age','n_siblings_spouses','parch','fare','class_enc','alone_enc',\n",
    "                               'sex_ohe','embark_ohe'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca=MinMaxScaler(inputCol='features',outputCol='features_mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu=KMeans(k=3)\n",
    "pipe=Pipeline(stages=[sex_enc,embark_enc,class_enc,alone_enc,ohe,vec,sca,clu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=pipe.fit(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion=modelo.transform(df1)\n",
    "#prediccion.select('prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhoutte 0.8185907502863816\n"
     ]
    }
   ],
   "source": [
    "evaluacion=ClusteringEvaluator()\n",
    "print('Silhoutte', evaluacion.evaluate(prediccion))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
