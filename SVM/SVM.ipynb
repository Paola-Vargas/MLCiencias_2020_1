{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator,VectorAssembler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    try:\n",
    "        from pyspark.sql import SparkSession\n",
    "    except:\n",
    "        import findspark\n",
    "        findspark.init()\n",
    "        from pyspark.sql import SparkSession\n",
    "    spark=SparkSession.builder \\\n",
    "    .master(\"local[8]\") \\\n",
    "    .appName(\"ejemplo\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTitanic=spark.read.csv(\"titanic_train.csv\",header=True,inferSchema=True)\n",
    "dataTitanic_test=spark.read.csv(\"titanic_eval.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------------------+------+------------------+------------------+------------------+------------------+-----+-------+-----------+-----+\n",
      "|summary|          Start.Time|           Stop Time|          survived|   sex|               age|n_siblings_spouses|             parch|              fare|class|   deck|embark_town|alone|\n",
      "+-------+--------------------+--------------------+------------------+------+------------------+------------------+------------------+------------------+-----+-------+-----------+-----+\n",
      "|  count|                 158|                 158|               627|   627|               627|               627|               627|               627|  627|    627|        627|  627|\n",
      "|   mean|1.558541201464107...|1.558541205959171E12|0.3875598086124402|  null|29.631307814992027|0.5454545454545454| 0.379585326953748|34.385398564593245| null|   null|       null| null|\n",
      "| stddev|  19793.234457004008|   3181.834167280871|0.4875821656114251|  null|12.511817629565812|1.1510895973422302|0.7929992125432801|54.597730499456304| null|   null|       null| null|\n",
      "|    min|       1558541042150|       1558541200369|                 0|female|              0.75|                 0|                 0|               0.0|First|      A|  Cherbourg|    n|\n",
      "|    max|       1558541210480|       1558541210480|                 1|  male|              80.0|                 8|                 5|          512.3292|Third|unknown|    unknown|    y|\n",
      "+-------+--------------------+--------------------+------------------+------+------------------+------------------+------------------+------------------+-----+-------+-----------+-----+\n",
      "\n",
      "None\n",
      "627\n",
      "root\n",
      " |-- Start.Time: long (nullable = true)\n",
      " |--  Stop Time: long (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- n_siblings_spouses: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- deck: string (nullable = true)\n",
      " |-- embark_town: string (nullable = true)\n",
      " |-- alone: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataTitanic.describe().show())\n",
    "print(dataTitanic.count())\n",
    "print(dataTitanic.printSchema())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataTitanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTitanic.createOrReplaceTempView(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   deck|\n",
      "+-------+\n",
      "|      F|\n",
      "|unknown|\n",
      "|      E|\n",
      "|      B|\n",
      "|      D|\n",
      "|      C|\n",
      "|      A|\n",
      "|      G|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" SELECT DISTINCT deck from titanic\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|embark_town|\n",
      "+-----------+\n",
      "|    unknown|\n",
      "| Queenstown|\n",
      "|Southampton|\n",
      "|  Cherbourg|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" SELECT DISTINCT embark_town from titanic\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sex=StringIndexer(inputCol=\"sex\",outputCol=\"sex_num\",stringOrderType=\"alphabetAsc\")\n",
    "enc_class=StringIndexer(inputCol=\"class\",outputCol=\"class_num\",stringOrderType=\"alphabetAsc\")\n",
    "enc_deck=StringIndexer(inputCol=\"deck\",outputCol=\"deck_num\",stringOrderType=\"alphabetAsc\")\n",
    "enc_embark=StringIndexer(inputCol=\"embark_town\",outputCol=\"embark_town_num\",stringOrderType=\"alphabetAsc\")\n",
    "enc_alone=StringIndexer(inputCol=\"alone\",outputCol=\"alone_num\",stringOrderType=\"frequencyAsc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoderEstimator(inputCols=[\"sex_num\",\"deck_num\",\"embark_town_num\"],\n",
    "                               outputCols=[\"sex_ohe\",\"deck_ohe\",\"embark_town_ohe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=VectorAssembler(inputCols=[\"sex_ohe\",\"age\",\"n_siblings_spouses\",\"parch\",\"fare\",\"class_num\",\"deck_ohe\",\n",
    "                                  \"embark_town_ohe\",\"alone_num\"],outputCol=\"covariables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scala=MinMaxScaler(inputCol=\"covariables\",outputCol=\"sca_covariables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearSVC(featuresCol=\"sca_covariables\",labelCol=\"survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuberia=Pipeline(stages=[enc_sex,enc_class,enc_deck,enc_embark,enc_alone,ohe,vector,scala,model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_train=tuberia.fit(dataTitanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|prediction|survived|\n",
      "+----------+--------+\n",
      "|       0.0|       0|\n",
      "|       1.0|       0|\n",
      "|       1.0|       1|\n",
      "|       1.0|       1|\n",
      "|       0.0|       1|\n",
      "|       1.0|       1|\n",
      "|       1.0|       0|\n",
      "|       0.0|       0|\n",
      "|       1.0|       0|\n",
      "|       1.0|       1|\n",
      "+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediccion=mod_train.transform(dataTitanic_test)\n",
    "prediccion.select(\"prediction\",\"survived\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=MulticlassClassificationEvaluator(\n",
    "predictionCol=\"prediction\",\n",
    "labelCol=\"survived\",\n",
    "metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7537878787878788"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.evaluate(prediccion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
